{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458bdf7d",
   "metadata": {},
   "source": [
    "# Loading Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3180fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616e35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from haystack import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317e96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162f8e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'content', 'content_type', 'meta', 'id_hash_keys', 'score', 'embedding'],\n",
       "    num_rows: 151\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe8152",
   "metadata": {},
   "source": [
    "Converting dataset's data into haystack document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917df496",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(content=doc['content'],meta = doc['meta'])for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f751287",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071e3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "#text_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f013cd4e",
   "metadata": {},
   "source": [
    "## Document Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f46625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder,SentenceTransformersTextEmbedder\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4cf975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31999830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345ebdb479c942309c1e3ee3a369cb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_with_embeddings = doc_embedder.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e562578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['documents'])\n"
     ]
    }
   ],
   "source": [
    "print(docs_with_embeddings.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "412c1ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.write_documents(docs_with_embeddings['documents'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cfffa",
   "metadata": {},
   "source": [
    "# retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09541949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d23eab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage\n",
    "template  =[ChatMessage.from_user( \"\"\"You are a helpful assistant. \n",
    "                                  Answer the question based on the  \n",
    "                                  context provided.\n",
    "                                  {% for document in documents %}\n",
    "                                    {{document.content}}\n",
    "                                    {% endfor %}\n",
    "                                    Question: {{question}}\n",
    "                                    Answer:\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b53d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Create a .env file with your API key\n",
    "# GOOGLE_API_KEY=your_api_key_here\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set API key from environment variable\n",
    "os.environ[\"Gemini_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\") or \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0871c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_builder = ChatPromptBuilder(template = template, required_variables={\"question\",\"documents\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "902bb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_integrations.components.generators.google_genai import GoogleGenAIChatGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf43d4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#from getpass import getpass\n",
    "from haystack_integrations.components.generators.google_genai import GoogleGenAIChatGenerator\n",
    "#if \"OPENAI_API_KEY\" not in os.environ:\n",
    "#    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")\n",
    "llm = GoogleGenAIChatGenerator(model=\"gemini-1.5-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55774aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… text_embedder created\n",
      "âœ… retriever created\n"
     ]
    }
   ],
   "source": [
    "if 'text_embedder' not in locals():\n",
    "    text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    text_embedder.warm_up()\n",
    "    print(\"âœ… text_embedder created\")\n",
    "else:\n",
    "    print(\"âœ… text_embedder already exists\")\n",
    "\n",
    "# 2. retriever (MISSING - needs to be recreated)\n",
    "if 'document_store' not in locals():\n",
    "    print(\"âŒ document_store not found! You need to run the document setup first.\")\n",
    "    print(\"Please run the document embedding setup code first.\")\n",
    "else:\n",
    "    retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "    print(\"âœ… retriever created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dd073cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"who wrote De septem mundi miraculis ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8ba374c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x000001ACD8BCFE90>\n",
       "ðŸš… Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: ChatPromptBuilder\n",
       "  - llm: GoogleGenAIChatGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (list[float])\n",
       "  - retriever.documents -> prompt_builder.documents (list[Document])\n",
       "  - prompt_builder.prompt -> llm.messages (list[ChatMessage])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "rag_pipeline = Pipeline()\n",
    "# âœ… CHANGE 2: Add text_embedder component to pipeline\n",
    "rag_pipeline.add_component(\"text_embedder\", text_embedder)  # NEW\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "# âœ… CHANGE 3: Connect components properly with query embedding\n",
    "rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")  # NEW CONNECTION\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3787edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c495c2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd39847478d4850afcf8bd805dee786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RAG = rag_pipeline.run({\n",
    "    \"text_embedder\": {\"text\": question},  # âœ… NEW: Provides query embedding\n",
    "    \"prompt_builder\": {\"question\": question}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c93d68ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ChatMessage(_role=<ChatRole.ASSISTANT: 'assistant'>, _content=[TextContent(text='Philo of Byzantium wrote *De septem mundi miraculis*.\\n')], _name=None, _meta={'model': 'gemini-1.5-flash', 'finish_reason': 'stop', 'usage': {'prompt_tokens': 2335, 'completion_tokens': 15, 'total_tokens': 2350}})]\n"
     ]
    }
   ],
   "source": [
    "# Execute the RAG pipeline if not already done\n",
    "print(RAG[\"llm\"][\"replies\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f9c30a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Philo of Byzantium wrote *De septem mundi miraculis*.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the RAG pipeline if not already done\n",
    "print(RAG[\"llm\"][\"replies\"][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25ddea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844212cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
